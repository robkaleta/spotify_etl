{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a307ca11-18ca-4ca4-8147-896c2beaf61b",
   "metadata": {},
   "source": [
    "# boto3 set up and access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7526a5b9-9cb1-4b12-82ec-b7eaf1498d1e",
   "metadata": {},
   "source": [
    "Create a credentials file (plain text) in the root folder `~/.aws/credentials`\n",
    "\n",
    "Format:\n",
    "\n",
    "[Profile Name]\n",
    "\n",
    "aws_access_key_id = xxx\n",
    "\n",
    "aws_secret_access_key = xxx/xxx\n",
    "\n",
    "AWS Credentials (if stored in the location above) will be automatically detected by`boto3` when establishing a connection.\n",
    "\n",
    "\n",
    "**Session** is where to initiate the connectivity to AWS services. E.g. following is default session that uses the default credential profile(e.g. ~/.aws/credentials, or assume your EC2 using IAM instance profile )\n",
    "\n",
    "**Resource** This is the high-level service class recommended to be used. This allows you to tied particular AWS resources and passes it along, so you just use this abstraction than worry which target services are pointed to.\n",
    "\n",
    "**Clients** provide a low-level interface to the AWS service. Their definitions are generated by a JSON service description present in the botocore library. The botocore package is shared between boto3 as well as the AWS CLI.\n",
    "\n",
    "To summarize, resources are higher-level abstractions of AWS services compared to clients. Resources are the recommended pattern to use boto3 as you don’t have to worry about a lot of the underlying details when interacting with AWS services. As a result, code written with Resources tends to be simpler.\n",
    "\n",
    "However, Resources aren’t available for all AWS services. In such cases, there is no other choice but to use a Client instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38db215-6af6-4bae-8d22-6e80dc671318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e55c68d-f853-4f44-84f8-8cb5e9f30cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "session = boto3.Session(\n",
    "    profile_name='Admin_Profile', \n",
    "    region_name= 'eu-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7f6871-8e45-4886-9c61-247b42b645d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = session.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c215237-e665-4c78-93f1-686dbbf7ef4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "buckets = s3.buckets.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e69ee94-4607-447a-9366-99eb29f6065f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.Bucket(name='spotify-etl-data')\n"
     ]
    }
   ],
   "source": [
    "for bucket in buckets:\n",
    "    print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d766a1af-f907-4dec-bbf0-49ef8a6d46ef",
   "metadata": {},
   "source": [
    "Let's try and load a file to the bucket on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24d2d1f-f6b7-4d8c-aba5-36741e922b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parquet_file_to_load = pd.read_parquet('tmp/rock_albums.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad38f30-4db2-4d46-af25-488c2416d931",
   "metadata": {},
   "source": [
    "Access the bucket in the S3 resource using the s3.Bucket() method and invoke the upload_file() method to upload the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad94157-e719-4e81-bc71-01c97bee69a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3.Bucket('spotify-etl-data').upload_file(Filename = 'tmp/rock_albums.parquet', Key='rock_albums.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b39db05b-7cbe-4bc9-8a95-fad1ba234c1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock_albums.parquet\n"
     ]
    }
   ],
   "source": [
    "for my_bucket_object in s3.Bucket('spotify-etl-data').objects.all():\n",
    "    print(my_bucket_object.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81948d63-f81e-4e60-a999-a18d7036025a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "664cad52-0736-48b6-968e-f3850cb8857f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_today = datetime.today().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fcda320-0239-415f-9617-45b3d6db3812",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-07-08'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5cfd86c-de6a-4f12-87bf-19183641ef8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_to_s3(local_path, key, bucket):\n",
    "    '''\n",
    "    Upload a file to S3\n",
    "    Needs a boto3 session amd resource to be set up and named s3\n",
    "    '''\n",
    "    try:\n",
    "        date_today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "        s3_filename = f'{date_today}_{key}'\n",
    "\n",
    "        s3.Bucket(bucket).upload_file(Filename = local_path, Key = s3_filename)\n",
    "        \n",
    "        print(f'Uploaded file {s3_filename} to {bucket}')\n",
    "    \n",
    "    except:\n",
    "        print('Something went wrong - check inputs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "789da5b4-b618-411e-bf78-272047c6ce97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong - check inputs\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3('tmp/rock_albums.parquet', key= 'rock_albums.parquet', bucket = 'spossssstify-etl-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ccd7f1-2d31-41f6-a3d0-f28e22ae4a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
